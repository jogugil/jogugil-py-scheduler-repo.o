# Lab: Building a Custom Kubernetes Scheduler in Python
##  Learning Objectives
 * By the end of this lab, you will:
    - Understand how the **scheduler** interacts with the **API Server**.
    - Implement a **custom scheduler** that:
    - Finds **Pending Pods** with a given `schedulerName`.
    - Chooses a **Node** according to a scheduling policy.
    - **Binds** the Pod to that Node through the Kubernetes API.
    - Compare **polling vs event-driven (watch)** models.
    - Deploy your scheduler into a **kind cluster** and observe its behavior.

  ---

# Realizaci√≥n de la pr√°ctica:
 ## üß∞ Step 0 ‚Äî Set up the environment
 
 We set up the environment using the required installation prerequisites. We then followed the steps described in 
 section `A` of the `README.md`.




 In the environment we prepared, we executed the first step:
 
 ## ‚öô Step 1 ‚Äî Observe the Default Scheduler-. 
 
 1. Identify the running scheduler
```Bash
kubectl -n kube-system get pods -l component=kube-scheduler
kubectl -n kube-system logs -l component=kube-scheduler
```
 2.  Schedule a simple pod:
```Bash
kubectl run test --image=nginx --restart=Never
kubectl get pods -o wide
```

### ‚úÖ**Checkpoint 1:**
Describe the path:
    kubectl run ‚Üí Pod created ‚Üí Scheduler assigns Node ‚Üí kubelet starts Pod.
 
<p align="center">
<img src="https://github.com/jogugil/jogugil-py-scheduler-repo.o/blob/main/img/fugura1-1.png" width="850">
  <br>
  <em>Figure 1: Verification of the default scheduler and scheduling of a test Pod.</em>
</p>

‚úÖ **Descripci√≥n del flujo de scheduling en Kubernetes**

La **Figura 1** muestra la ejecuci√≥n de los comandos utilizados para verificar que el scheduler por defecto est√° en funcionamiento y para observar c√≥mo se programa un Pod sencillo dentro del cl√∫ster creado con Kind. A partir de los resultados obtenidos, podemos describir el funcionamiento interno del sistema cuando programamos un Pod:

**a) Enviamos la orden de creaci√≥n del Pod**  
Ejecutamos `kubectl run test --image=nginx --restart=Never`, lo que provoca que el cliente `kubectl` env√≠e al API Server un objeto Pod para ser creado. En este momento, el Pod se registra pero a√∫n no tiene un nodo asignado.

**b) El Pod queda inicialmente en estado *Pending***  
Tras su creaci√≥n, el API Server almacena el Pod con `status=Pending`, ya que todav√≠a no ha sido asociado a ning√∫n nodo del cl√∫ster.

**c) El scheduler detecta el nuevo Pod sin asignar**  
El `kube-scheduler`, que aparece ejecut√°ndose como se muestra en la Figura 1, observa peri√≥dicamente los Pods pendientes mediante sus mecanismos internos de *informers*.  
Detecta que el Pod reci√©n creado no tiene un nodo asociado (`.spec.nodeName` vac√≠o).

**d) El scheduler selecciona un nodo adecuado**  
Una vez detectado el Pod pendiente, el scheduler eval√∫a los nodos disponibles.  
En nuestro entorno Kind, la asignaci√≥n habitual es al nodo de control (`sched-lab-control-plane`).  
El scheduler realiza entonces el *binding* del Pod, actualizando su campo `.spec.nodeName`.

**e) El kubelet del nodo asignado inicia el contenedor**  
Tras el binding, el kubelet del nodo seleccionado recibe la nueva especificaci√≥n, descarga la imagen `nginx` si no est√° disponible y comienza a crear el contenedor.  
El estado del Pod pasa a `ContainerCreating` y finalmente a `Running`.

En conjunto, estos pasos confirman que el flujo interno es el esperado:

**kubectl run ‚Üí API Server crea el Pod ‚Üí Scheduler asigna nodo ‚Üí Kubelet ejecuta el contenedor**,  
tal como se observa en la secuencia mostrada en **Figura 2**.



 ## üß± Step 2 ‚Äî Project Setup

 Initialize Project
 
 ```Bash
mkdir py-scheduler && cd py-scheduler
python -m venv .venv && source .venv/bin/activate
pip install kubernetes==29.0.0
touch scheduler.py
 ```
Directory Structure

 ```Bash
py-scheduler/
‚îú‚îÄ‚îÄ scheduler.py
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ rbac-deploy.yaml
‚îú‚îÄ‚îÄ test-pod.yaml
‚îî‚îÄ‚îÄ requirements.txt
 ```

<p align="center">
<img src="https://github.com/jogugil/jogugil-py-scheduler-repo.o/blob/main/img/Figura2.png" width="850">
  <br>
  <em>Figure 2: We create the local directory containing the files required to deploy the polling scheduler.</em>

</p>

## üß† Step 3 ‚Äî Implement the Polling Scheduler
### ‚úÖ**Checkpoint 2:**

***Understand the control loop:***
    - **Observe**: *list unscheduled Pods:*    
    - **Decide**: *pick a Node*       
    - **Act**: *bind the Pod*

Para implementar el scheduler basado en *polling*, se ha seguido el patr√≥n cl√°sico de los controladores de Kubernetes: **Observar ‚Üí Decidir ‚Üí Actuar**. El c√≥digo proporcionado ([variants/polling/scheduler.py](https://github.com/jogugil/jogugil-py-scheduler-repo.o/blob/main/variants/polling/scheduler.py)
) implementa este ciclo mediante consultas peri√≥dicas al API Server. A continuaci√≥n describimos cada fase y su relaci√≥n directa con el c√≥digo del scheduler.

---

‚úÖ **1. Observar: listar los Pods no programados**

En el bucle principal, el scheduler consulta peri√≥dicamente al API Server para obtener los Pods que cumplen:

- **no tienen nodo asignado**, es decir, est√°n en estado `Pending` (`spec.nodeName=`), y  
- **solicitan expl√≠citamente el scheduler personalizado** (`spec.schedulerName == args.scheduler_name`) (Debe ser `my_scheduler`).

```python
pods = api.list_pod_for_all_namespaces(
    field_selector="spec.nodeName="
).items

for pod in pods:
    if pod.spec.scheduler_name != args.scheduler_name:
        continue
```
  As√≠, s√≥lo cogemos los Pods pendientes de asignaci√≥n, es decir, que a√∫n no tienen un nodo asignado (spec.nodeName vac√≠o), lo que normalmente corresponde a Pods en estado Pending.
  
 ‚úÖ 2. Decidir: seleccionar un nodo
La l√≥gica de decisi√≥n est√° en:
 ```python
node = choose_node(api, pod)
 ```
La funci√≥n `choose_node()` realiza lo siguiente:
        a. Obtiene la lista completa de nodos: `nodes = api.list_node().items`
        b. Cuenta cu√°ntos Pods est√°n ya asignados a cada nodo: `cnt = sum(1 for p in pods if p.spec.node_name == n.metadata.name)`
        c. Selecciona el nodo con menos Pods, aplicando as√≠ una estrategia sencilla de ‚Äúmenor carga‚Äù: `if cnt < min_cnt:`
 
   ‚úÖ 3. Actuar: realizar el binding del Pod√ß
    ```python
   bind_pod(api, pod, node_name)
    ```
El binding consiste en:
    a) crear una referencia al nodo: `target = client.V1ObjectReference(kind="Node", name=node_name)`
    b) crear la estructura V1Binding: `body = client.V1Binding(target=target, metadata=client.V1ObjectMeta(name=pod.metadata.name))`
    c) enviarla al API Server para completar la asignaci√≥n: `api.create_namespaced_binding(pod.metadata.namespace, body)`

Este paso actualiza el campo .spec.nodeName del Pod.  Y a partir de aqu√≠, el kubelet del nodo asignado detecta la nueva asignaci√≥n y comienza la creaci√≥n del contenedor correspondiente.
    
## üê≥üîêüß™ Step 4 5 y 6 ‚Äî Build and Deploy. RBAC & Deployment. Test Your Scheduler


### ‚úÖ**Checkpoint 3:**

***Your scheduler should log a message like:***
    - Bound default/test-pod -> kind-control-plane

## üß© Step 7 ‚Äî Event-Driven Scheduler (Watch API)

### ‚úÖ**Checkpoint 4:**
***Compare responsiveness and efficiency between polling and watch approaches.***

## üß© Step 8 ‚Äî Policy Extensions

1. Label-based node filtering
```Bash
nodes = [n for n in api.list_node().items
if "env" in (n.metadata.labels or {}) and
n.metadata.labels["env"] == "prod"]
```
2. Taints and tolerations Use `node.spec.taints` and `pod.spec.tolerations` to filter nodes
before scoring.
3. Backoff / Retry Use exponential backoff when binding fails due to transient API errors.
4. Spread policy Distribute similar Pods evenly across Nodes.

### ‚úÖ **Checkpoint 5:**
***Demonstrate your extended policy via pod logs and placement.***


# üß†Reflection Discussion


- ***Why is it important that your scheduler writes a Binding object instead of patching a Pod directly?***
  
> ### Importancia de usar un `Binding` en lugar de modificar directamente un Pod
>
> Porque el uso de un `Binding` es el mecanismo definido por Kubernetes para asignar un Pod a un nodo.  
> En un principio, este mecanismo permite escalabilidad y fiabilidad del cl√∫ster, ya que comprueba si los nodos tienen permisos para ejecutar dicho Pod y si la carga del nodo permite ejecutarlo. Esto permite mantener un balance de carga y garantizar la seguridad en la ejecuci√≥n de los contenedores.  
> La asignaci√≥n se realiza de forma **at√≥mica y segura**, es decir, o se asigna o no se asigna, evitando condiciones de carrera.  
> 
> Adem√°s, todo se realiza a trav√©s del **API Server**, lo que garantiza que el flujo de control sea el correcto dentro del sistema. Esto permite tambi√©n mantener un sistema **auditable**, √∫til para depuraci√≥n y trazabilidad.

- ***What are the trade-offs between polling vs event-driven models?***

> ### Ventajas y desventajas del modelo de polling
>
> **Ventajas:**
> - Muy f√°cil de implementar.  
> - No necesita controladores sofisticados.  
> - Tolera fallos temporales de conexi√≥n.
>
> **Desventajas:**
> - Introduce **latencia**: un Pod puede tardar en ser detectado.  
> - Genera **carga innecesaria** en el API Server por las consultas repetidas.  
> - No escala bien en cl√∫steres grandes.
 
- ***How do taints and tolerations interact with your scheduling logic?***

> - Un **taint** en un nodo sirve para ‚Äúrepeler‚Äù Pods que no lo toleren.  
> - Una **toleration** en un Pod indica que puede ejecutarse en un nodo con ese taint.
>
> Para un scheduler personalizado:
> - a) Debemos **filtrar nodos cuyo taint no pueda ser tolerado** por el Pod.  
> - b) Si ignoramos esto, podr√≠amos bindear un Pod a un nodo donde **nunca podr√° ejecutarse**, quedando permanentemente en `Pending`.  
>
> **Ejemplo:**  
> Un Pod sin tolerations **no debe** ser programado en un nodo con el taint `NoSchedule`.
>
> Por tanto, un scheduler completo debe:
> - Leer los taints del nodo.  
> - Leer las tolerations del Pod.  
> - Excluir nodos incompatibles antes de tomar una decisi√≥n.
 
- ***What are real-world policies you could implement using this framework?***

> El framework permite implementar pol√≠ticas reales como:
>
> - a) ***[Nodo menos cargado](https://kubernetes.io/docs/concepts/scheduling-eviction/scheduler-perf-tuning/)*** (la que usamos).
>
> - b) ***[Resource Bin Packing](https://kubernetes.io/docs/concepts/scheduling-eviction/resource-bin-packing/)***: llenar nodos al m√°ximo antes de usar nuevos.
>
> - c) ***[Affinity y Anti-affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)***  
>     - Separar cargas sensibles.  
>     - Agrupar Pods que trabajan juntos.
>
> - d) ***Ahorro energ√©tico***  
>     - Consolidar cargas para apagar nodos poco usados.  
>     - Elegir nodos m√°s eficientes.
>
> - e) ***Topolog√≠a y rendimiento***  
>     - Elegir nodos seg√∫n regi√≥n, zona, latencia, GPU‚Ä¶  
>     - [Topology Spread Constraints](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/)  
>     - [Node Labels](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels)  
>     - [Topology Manager / NUMA](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-manager/)
>
> - f) ***Prioridades y SLAs***  
>     - Colocar Pods prioritarios en nodos espec√≠ficos.  
>     - [Pod Priority & Preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/)  
>     - [QoS Classes](https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/)

